{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.auto import partition\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from langchain_core.documents import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path, dirs, files = next(os.walk(path))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for file in files:\n",
    "    with open( os.path.join(path, file), 'rb') as f:\n",
    "        print(f'Opening file: {file}')\n",
    "        \n",
    "        # open file, clean, segment\n",
    "        elements = partition(file=f)\n",
    "        \n",
    "        # create chunks to better rag\n",
    "        chunks = chunk_by_title(elements, max_characters=1500, new_after_n_chars=1000, overlap=150)\n",
    "        \n",
    "        # convert to the Langchain format\n",
    "        for chunk in chunks:\n",
    "            metadata = chunk.metadata.to_dict()\n",
    "            # print(\"---------------------\")\n",
    "            # print(metadata)\n",
    "            # print(\"---------------------\")\n",
    "            # print(chunk.text)\n",
    "\n",
    "            del metadata[\"languages\"]\n",
    "            if \"filename\" in metadata:\n",
    "                metadata[\"source\"] = metadata[\"filename\"]\n",
    "            else:\n",
    "                metadata[\"source\"] = file\n",
    "\n",
    "            documents.append(Document(page_content=chunk.text, metadata=metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "model_name = \"nomic-embed-text-v1.f16.gguf\"\n",
    "gpt4all_kwargs = {'allow_download': 'True'}\n",
    "embeddings = GPT4AllEmbeddings(\n",
    "    model_name=model_name,\n",
    "    gpt4all_kwargs=gpt4all_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"index1\"\n",
    "url = 'host.docker.internal'\n",
    "url2 = 'http://host.docker.internal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "weaviate_client = weaviate.connect_to_custom(\n",
    "    http_host=url,\n",
    "    http_port=8080,\n",
    "    http_secure=False,\n",
    "    grpc_host=url,\n",
    "    grpc_port=50051,\n",
    "    grpc_secure=False,\n",
    "    # auth_credentials=AuthApiKey(weaviate_key),   # `weaviate_key`: your Weaviate API key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "\n",
    "vector_store = WeaviateVectorStore.from_documents(documents, embeddings, client=weaviate_client, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = WeaviateVectorStore(weaviate_client, index_name, \"text_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,  # Define o nível de log\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',  # Define o formato da mensagem de log\n",
    "                    stream=sys.stdout)  # Define a saída do log para stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Assuming the notebook is in 'app/lab' and the module is in 'app/app'\n",
    "module_path = os.path.abspath(os.path.join('..', 'app'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-20 00:25:20,192 - INFO - Importing files to the vector store\n",
      "Opening file: Cadastramento inicial no PJe.pdf\n",
      "2024-05-20 00:25:45,626 - INFO - pikepdf C++ to Python logger bridge initialized\n",
      "Opening file: guiapje-advogados.pdf\n",
      "2024-05-20 00:25:56,676 - INFO - HTTP Request: GET http://host.docker.internal:8080/v1/.well-known/openid-configuration \"HTTP/1.1 404 Not Found\"\n",
      "2024-05-20 00:25:56,842 - INFO - HTTP Request: GET http://host.docker.internal:8080/v1/meta \"HTTP/1.1 200 OK\"\n",
      "2024-05-20 00:25:57,048 - INFO - HTTP Request: GET https://pypi.org/pypi/weaviate-client/json \"HTTP/1.1 200 OK\"\n",
      "2024-05-20 00:25:57,328 - INFO - HTTP Request: GET http://host.docker.internal:8080/v1/schema/Index2 \"HTTP/1.1 404 Not Found\"\n",
      "2024-05-20 00:25:57,435 - INFO - HTTP Request: POST http://host.docker.internal:8080/v1/schema \"HTTP/1.1 200 OK\"\n",
      "2024-05-20 00:25:57,440 - INFO - HTTP Request: GET http://host.docker.internal:8080/v1/schema/Index2 \"HTTP/1.1 200 OK\"\n",
      "2024-05-20 00:26:11,644 - INFO - HTTP Request: GET http://host.docker.internal:8080/v1/schema \"HTTP/1.1 200 OK\"\n",
      "2024-05-20 00:26:11,648 - INFO - HTTP Request: GET http://host.docker.internal:8080/v1/nodes \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ingestion succesfull'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ingest import ingest\n",
    "\n",
    "ingest.ingest_path(\"../../docs_2\", \"index2\", logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
